    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.self.mrdsj.MetricsRealsPrunedEpsilon --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS 1
      spark-submit --class gr.ds.unipi.self.mrdsj.MetricsRealsPrunedTwoEpsilon --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS 1
      spark-submit --class gr.ds.unipi.self.processing.MetricsRealsPruned --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS 0.001
      if [ "$i" != "0.012" ]; then
        spark-submit --class gr.ds.unipi.self.processing.stripes.MetricsRealsPruned --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS 0.001
      fi
      spark-submit --class gr.ds.unipi.self.sedona.MetricsDistanceJoinReal --master yarn --deploy-mode client --jars=./libSedona/* --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS 960 276000000
    done

    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.self.mrdsj.MetricsRealsPrunedEpsilon --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} LINEARWATER 1
      spark-submit --class gr.ds.unipi.self.mrdsj.MetricsRealsPrunedTwoEpsilon --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} LINEARWATER 1
      spark-submit --class gr.ds.unipi.self.processing.MetricsRealsPruned --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} LINEARWATER 0.001
      if [ "$i" != "0.012" ]; then
        spark-submit --class gr.ds.unipi.self.processing.stripes.MetricsRealsPruned --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} LINEARWATER 0.001
      fi
      spark-submit --class gr.ds.unipi.self.sedona.MetricsDistanceJoinReal --master yarn --deploy-mode client --jars=./libSedona/* --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} LINEARWATER 960 278000000
    done

    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.self.mrdsj.MetricsRealsPrunedEpsilon --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER 1
      spark-submit --class gr.ds.unipi.self.mrdsj.MetricsRealsPrunedTwoEpsilon --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER 1
      spark-submit --class gr.ds.unipi.self.processing.MetricsRealsPruned --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER 0.001
      if [ "$i" != "0.012" ]; then
        spark-submit --class gr.ds.unipi.self.processing.stripes.MetricsRealsPruned --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.executor.memoryOverhead=1g --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER 0.001
      fi
      spark-submit --class gr.ds.unipi.self.sedona.MetricsDistanceJoinReal --master yarn --deploy-mode client --jars=./libSedona/* --executor-memory 5g --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER 960 94000000
    done
