for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS AREAWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS AREAWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS AREAWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS AREAWATER 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS AREAWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=765m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS AREAWATER 42700000 94000000 960
      ./yarnState.sh || exit 1
    done
done


for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS AREAWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS AREAWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS AREAWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS AREAWATER 0.001 960 LPT1
      if [ "$i" != "0.012" ]; then
        spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS AREAWATER 960 DIAG_PR 0.001 LPT1
      fi
      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS AREAWATER 58700000 94000000 960
      ./yarnState.sh || exit 1
    done
done



for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS LINEARWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS LINEARWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS LINEARWATER 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS LINEARWATER 42700000 278000000 960
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS ROADS 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS ROADS 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS ROADS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS ROADS 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS ROADS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS ROADS 42700000 276000000 960
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER ROADS 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER ROADS 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER ROADS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER ROADS 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER ROADS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER ROADS 94000000 276000000 960
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS ROADS 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS ROADS 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS ROADS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS ROADS 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS ROADS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS ROADS 58700000 276000000 960
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS LINEARWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS LINEARWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS LINEARWATER 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS LINEARWATER 58700000 278000000 960
      ./yarnState.sh || exit 1
    done
done



for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER LINEARWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER LINEARWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER LINEARWATER 0.001 960 LPT1
      if [ "$i" != "0.012" ]; then
        spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER LINEARWATER 960 DIAG_PR 0.001 LPT1
      fi
      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER LINEARWATER 94000000 278000000 960
      ./yarnState.sh || exit 1
    done
done



for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS LINEARWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS LINEARWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 ROADS LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS LINEARWATER 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 ROADS LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS LINEARWATER 276000000 278000000 960
      ./yarnState.sh || exit 1
    done
done


for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS BUILDINGS 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS BUILDINGS 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS BUILDINGS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS BUILDINGS 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS BUILDINGS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS BUILDINGS 42700000 58000000 960
      ./yarnState.sh || exit 1
    done
done



for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} datasetA100000000 datasetB100000000 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} datasetA100000000 datasetB100000000 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 datasetA100000000 datasetB100000000 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} datasetA100000000 datasetB100000000 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 datasetA100000000 datasetB100000000 960 DIAG_PR 0.001 LPT1
#      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} datasetA100000000 datasetB100000000 100000000 100000000 960
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} datasetA200000000 datasetB200000000 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} datasetA200000000 datasetB200000000 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 datasetA200000000 datasetB200000000 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} datasetA200000000 datasetB200000000 0.001 960 LPT1
      if [ "$i" != "0.012" ]; then
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 datasetA200000000 datasetB200000000 960 DIAG_PR 0.001 LPT1
      fi
#      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} datasetA200000000 datasetB200000000 200000000 200000000 960
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER datasetA100000000 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER datasetA100000000 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER datasetA100000000 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER datasetA100000000 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER datasetA100000000 960 DIAG_PR 0.001 LPT1
#      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER datasetA100000000 94000000 100000000 960
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER datasetA200000000 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER datasetA200000000 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER datasetA200000000 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER datasetA200000000 0.001 960 LPT1
      if [ "$i" != "0.012" ]; then
        spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER datasetA200000000 960 DIAG_PR 0.001 LPT1
      fi
#      spark-submit --class gr.ds.unipi.sedona.DistanceJoinReal --master yarn --deploy-mode client  --jars=./libSedona/* --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER datasetA100000000 94000000 100000000 960
      ./yarnState.sh || exit 1
    done
done




for j in $(seq 1 1 5); do
    for i in 1000000000 800000000 600000000 400000000; do
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ 0.006 datasetA${i} datasetB${i} 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ 0.006 4 datasetA${i} datasetB${i} 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ 0.006 datasetA${i} datasetB${i} 0.001 960 LPT1
      ./yarnState.sh || exit 1
    done
done





































for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS AREAWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS AREAWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS AREAWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS AREAWATER 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS AREAWATER 960 DIAG_PR 0.001 LPT1
      ./yarnState.sh || exit 1
    done
done


for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS AREAWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS AREAWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS AREAWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS AREAWATER 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS AREAWATER 960 DIAG_PR 0.001 LPT1
      ./yarnState.sh || exit 1
    done
done



for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS LINEARWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS LINEARWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS LINEARWATER 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS LINEARWATER 960 DIAG_PR 0.001 LPT1
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS ROADS 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS ROADS 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS ROADS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} PARKS ROADS 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 PARKS ROADS 960 DIAG_PR 0.001 LPT1
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER ROADS 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER ROADS 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER ROADS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER ROADS 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER ROADS 960 DIAG_PR 0.001 LPT1
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS ROADS 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS ROADS 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS ROADS 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS ROADS 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS ROADS 960 DIAG_PR 0.001 LPT1
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS LINEARWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS LINEARWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} BUILDINGS LINEARWATER 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 BUILDINGS LINEARWATER 960 DIAG_PR 0.001 LPT1
      ./yarnState.sh || exit 1
    done
done



for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER LINEARWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER LINEARWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} AREAWATER LINEARWATER 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 AREAWATER LINEARWATER 960 DIAG_PR 0.001 LPT1
      ./yarnState.sh || exit 1
    done
done



for j in $(seq 1 1 5); do
    for i in 0.012 0.009 0.006 0.003; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS LINEARWATER 960
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS LINEARWATER 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 ROADS LINEARWATER 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} ROADS LINEARWATER 0.001 960 LPT1
      spark-submit --class gr.ds.unipi.rdd.variant.stripes.GridTimeRealsPrunedPlaneSweepX  --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ ${i} 4 ROADS LINEARWATER 960 DIAG_PR 0.001 LPT1
      ./yarnState.sh || exit 1
    done
done

for j in $(seq 1 1 5); do
    for i in 1000000000 800000000 600000000 400000000; do
      spark-submit --class gr.ds.unipi.twoEpsilongrid.GridTimeDistRealsPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ 0.006 datasetA${i} datasetB${i} 960
      spark-submit --class gr.ds.unipi.rdd.GridTimeRealsPrunedPlaneSweep --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ 0.006 4 datasetA${i} datasetB${i} 960 DIAG_PR 0.001 LPT1
      spark-submit --class gr.ds.unipi.processing.GridTimeRealsPrunedPlaneSweepV --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ 0.006 datasetA${i} datasetB${i} 0.001 960 LPT1
      ./yarnState.sh || exit 1
    done
done


for j in $(seq 1 1 5); do
    for i in 1000000000 800000000 600000000 400000000; do
      spark-submit --class gr.ds.unipi.epsilongrid.GridTimeDistRealsBruteForce --master yarn --deploy-mode client --conf spark.yarn.archive="hdfs://node13:9000/user/spark-jars.tar.gz" --executor-memory 4608m --executor-cores 2 --driver-memory 6g --num-executors 12 --conf spark.network.timeout=1000000s --conf spark.shuffle.io.maxRetries=10 --conf spark.kryoserializer.buffer.max=2047m --conf "spark.executor.extraJavaOptions=-Xms4608m" --conf "spark.driver.extraJavaOptions=-Xms6g" --conf spark.executor.memoryOverhead=512m ~/Spatial-Joins-1.0-SNAPSHOT.jar hdfs://node13:9000/user/user/synth-skewed/pruned/ 0.006 datasetA${i} datasetB${i} 960
      ./yarnState.sh || exit 1
    done
done
